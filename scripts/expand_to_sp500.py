"""
S&P 500 ì „ì²´ ê¸°ì—…ìœ¼ë¡œ ë°ì´í„°ë² ì´ìŠ¤ í™•ì¥
í˜„ì¬ Top 100ì—ì„œ S&P 500 ì „ì²´ë¡œ í™•ì¥í•©ë‹ˆë‹¤.

ë°ì´í„° ì†ŒìŠ¤:
- S&P 500 ëª©ë¡: ìœ„í‚¤í”¼ë””ì•„
- CIK ì •ë³´: SEC EDGAR API
- ê¸°ì—… ìƒì„¸ ì •ë³´: Finnhub API
- í•œê¸€ ì´ë¦„: OpenAI API ë²ˆì—­
"""

import os
import sys
import time
import pandas as pd
import requests
from pathlib import Path
from typing import List, Dict, Optional
from dotenv import load_dotenv
from openai import OpenAI

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.data.supabase_client import SupabaseClient
from src.data.finnhub_client import FinnhubClient

load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


def get_sp500_tickers() -> pd.DataFrame:
    """S&P 500 ê¸°ì—… ë¦¬ìŠ¤íŠ¸ë¥¼ ìœ„í‚¤í”¼ë””ì•„ì—ì„œ ê°€ì ¸ì˜¤ê¸°"""
    url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"

    try:
        # User-Agent í—¤ë” ì¶”ê°€ (403 ë°©ì§€)
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()

        # ìœ„í‚¤í”¼ë””ì•„ í…Œì´ë¸” ì½ê¸°
        tables = pd.read_html(response.text)
        sp500_table = tables[0]

        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        sp500_df = sp500_table[
            [
                "Symbol",
                "Security",
                "GICS Sector",
                "GICS Sub-Industry",
                "Headquarters Location",
            ]
        ]
        sp500_df.columns = [
            "ticker",
            "company_name",
            "sector",
            "industry",
            "headquarters",
        ]

        # í‹°ì»¤ ì •ë¦¬ (ì  ì œê±° ë“±)
        sp500_df["ticker"] = sp500_df["ticker"].str.replace(".", "-", regex=False)

        print(f"âœ… S&P 500 ê¸°ì—… {len(sp500_df)}ê°œ ë¡œë“œ ì™„ë£Œ")
        return sp500_df

    except Exception as e:
        print(f"âŒ S&P 500 ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return pd.DataFrame()


def get_cik_map() -> Dict[str, str]:
    """SECì—ì„œ í‹°ì»¤-CIK ë§¤í•‘ ê°€ì ¸ì˜¤ê¸°"""
    print("ğŸ“‹ SECì—ì„œ CIK ë§¤í•‘ ë¡œë“œ ì¤‘...")

    headers = {
        "User-Agent": os.getenv("SEC_API_USER_AGENT", "researcher@university.edu"),
        "Accept": "application/json",
    }

    try:
        url = "https://www.sec.gov/files/company_tickers.json"
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        data = response.json()

        cik_map = {}
        for item in data.values():
            ticker = item.get("ticker", "").upper()
            cik = str(item.get("cik_str", "")).zfill(10)
            cik_map[ticker] = cik

        print(f"   {len(cik_map)}ê°œ CIK ë§¤í•‘ ë¡œë“œë¨")
        return cik_map

    except Exception as e:
        print(f"âš ï¸  CIK ë§¤í•‘ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}


def translate_to_korean(company_name: str) -> str:
    """ì˜ë¬¸ íšŒì‚¬ëª…ì„ í•œê¸€ë¡œ ë²ˆì—­ (OpenAI ì‚¬ìš©)"""
    try:
        response = openai_client.chat.completions.create(
            model=os.getenv("CHAT_MODEL", "gpt-4.1-mini"),
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ë¯¸êµ­ ê¸°ì—…ëª…ì„ í•œê¸€ë¡œ ë²ˆì—­í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë„ë¦¬ ì•Œë ¤ì§„ í•œê¸€ í‘œê¸°ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ ë°œìŒì„ í•œê¸€ë¡œ í‘œê¸°í•˜ì„¸ìš”. íšŒì‚¬ëª…ë§Œ ë°˜í™˜í•˜ì„¸ìš”.",
                },
                {
                    "role": "user",
                    "content": f"ë‹¤ìŒ ë¯¸êµ­ ê¸°ì—…ëª…ì„ í•œê¸€ë¡œ ë²ˆì—­í•˜ì„¸ìš”: {company_name}",
                },
            ],
            max_tokens=50,
            temperature=0.1,
        )
        korean_name = response.choices[0].message.content.strip()
        return korean_name
    except Exception as e:
        print(f"    âš ï¸ ë²ˆì—­ ì‹¤íŒ¨: {e}")
        return None


def translate_batch(company_names: List[str], batch_size: int = 20) -> Dict[str, str]:
    """ì—¬ëŸ¬ íšŒì‚¬ëª…ì„ ë°°ì¹˜ë¡œ ë²ˆì—­ (API í˜¸ì¶œ ìµœì†Œí™”)"""
    translations = {}

    for i in range(0, len(company_names), batch_size):
        batch = company_names[i : i + batch_size]
        batch_text = "\n".join([f"{j+1}. {name}" for j, name in enumerate(batch)])

        try:
            response = openai_client.chat.completions.create(
                model=os.getenv("CHAT_MODEL", "gpt-4.1-mini"),
                messages=[
                    {
                        "role": "system",
                        "content": """ë‹¹ì‹ ì€ ë¯¸êµ­ ê¸°ì—…ëª…ì„ í•œê¸€ë¡œ ë²ˆì—­í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë„ë¦¬ ì•Œë ¤ì§„ í•œê¸€ í‘œê¸°ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ ë°œìŒì„ í•œê¸€ë¡œ í‘œê¸°í•˜ì„¸ìš”.
ê° ì¤„ì— ë²ˆí˜¸ì™€ í•œê¸€ íšŒì‚¬ëª…ë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì˜ˆ: "1. ì• í”Œ""",
                    },
                    {
                        "role": "user",
                        "content": f"ë‹¤ìŒ ë¯¸êµ­ ê¸°ì—…ëª…ë“¤ì„ í•œê¸€ë¡œ ë²ˆì—­í•˜ì„¸ìš”:\n{batch_text}",
                    },
                ],
                max_tokens=1000,
                temperature=0.1,
            )

            result = response.choices[0].message.content.strip()
            lines = result.split("\n")

            for j, line in enumerate(lines):
                if j < len(batch):
                    # "1. ì• í”Œ" í˜•ì‹ì—ì„œ í•œê¸€ëª… ì¶”ì¶œ
                    if ". " in line:
                        korean_name = line.split(". ", 1)[1].strip()
                    else:
                        korean_name = line.strip()
                    translations[batch[j]] = korean_name

            print(f"    ğŸ“ {i+1}~{min(i+batch_size, len(company_names))}ê°œ ë²ˆì—­ ì™„ë£Œ")
            time.sleep(0.5)  # Rate limit

        except Exception as e:
            print(f"    âš ï¸ ë°°ì¹˜ ë²ˆì—­ ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨í•œ ë°°ì¹˜ëŠ” ê°œë³„ ë²ˆì—­ ì‹œë„
            for name in batch:
                korean = translate_to_korean(name)
                if korean:
                    translations[name] = korean

    return translations


def get_existing_tickers() -> List[str]:
    """í˜„ì¬ DBì— ìˆëŠ” ê¸°ì—… í‹°ì»¤ ëª©ë¡"""
    try:
        companies_df = SupabaseClient.get_all_companies()
        existing_tickers = companies_df["ticker"].tolist()
        print(f"ğŸ“Š í˜„ì¬ DBì— {len(existing_tickers)}ê°œ ê¸°ì—… ì¡´ì¬")
        return existing_tickers
    except Exception as e:
        print(f"âš ï¸  ê¸°ì¡´ í‹°ì»¤ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []


def get_missing_companies(
    sp500_df: pd.DataFrame, existing_tickers: List[str]
) -> pd.DataFrame:
    """ì•„ì§ DBì— ì—†ëŠ” ê¸°ì—… ì°¾ê¸°"""
    missing_df = sp500_df[~sp500_df["ticker"].isin(existing_tickers)]
    print(f"ğŸ” ì¶”ê°€í•  ê¸°ì—…: {len(missing_df)}ê°œ")
    return missing_df


def fetch_company_profile_from_finnhub(
    ticker: str, finnhub_client: FinnhubClient
) -> Optional[Dict]:
    """Finnhubì—ì„œ ê¸°ì—… í”„ë¡œí•„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    try:
        profile = finnhub_client.get_company_profile(ticker)
        if profile:
            return {
                "ticker": ticker,
                "company_name": profile.get("name", ""),
                "sector": profile.get("finnhubIndustry", ""),
                "exchange": profile.get("exchange", ""),
                "market_cap": profile.get("marketCapitalization", 0),
                "logo_url": profile.get("logo", ""),  # logo -> logo_url
                "website": profile.get("weburl", ""),  # weburl -> website
            }
        return None
    except Exception as e:
        print(f"  âš ï¸  {ticker} í”„ë¡œí•„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None


def add_companies_to_db(
    missing_df: pd.DataFrame,
    cik_map: Dict[str, str],
    korean_names: Dict[str, str],
    batch_size: int = 10,
):
    """ìƒˆ ê¸°ì—…ì„ DBì— ì¶”ê°€"""
    finnhub_client = FinnhubClient()
    client = SupabaseClient.get_client()

    total = len(missing_df)
    success_count = 0
    fail_count = 0

    print(f"\nğŸ“¤ {total}ê°œ ê¸°ì—…ì„ DBì— ì¶”ê°€ ì¤‘...")

    for idx, row in missing_df.iterrows():
        ticker = row["ticker"]
        company_name = row["company_name"]

        try:
            # Finnhubì—ì„œ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            profile = fetch_company_profile_from_finnhub(ticker, finnhub_client)

            # CIK ê°€ì ¸ì˜¤ê¸°
            cik = cik_map.get(ticker) or cik_map.get(ticker.replace("-", ""))

            # í•œê¸€ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
            korean_name = korean_names.get(company_name)

            if profile:
                # DBì— ì‚½ì… (DB ìŠ¤í‚¤ë§ˆì— ë§ì¶¤)
                company_data = {
                    "ticker": ticker,
                    "company_name": profile["company_name"] or company_name,
                    "cik": cik,
                    "sector": profile["sector"] or row["sector"],
                    "industry": row["industry"],
                    "exchange": profile["exchange"],
                    "market_cap": profile["market_cap"],
                    "logo_url": profile["logo_url"],
                    "website": profile["website"],
                    "headquarters": row.get("headquarters"),
                    "korean_name": korean_name,
                }
            else:
                # Finnhub ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì •ë³´ë§Œ ì‚¬ìš©
                company_data = {
                    "ticker": ticker,
                    "company_name": company_name,
                    "cik": cik,
                    "sector": row["sector"],
                    "industry": row["industry"],
                    "headquarters": row.get("headquarters"),
                    "korean_name": korean_name,
                }

            result = client.table("companies").insert(company_data).execute()

            if result.data:
                success_count += 1
                kr_display = f" ({korean_name})" if korean_name else ""
                print(
                    f"  âœ… {success_count}/{total} - {ticker}: {company_data['company_name'][:30]}{kr_display}"
                )
            else:
                fail_count += 1
                print(f"  âŒ {ticker} ì‚½ì… ì‹¤íŒ¨")

        except Exception as e:
            fail_count += 1
            print(f"  âŒ {ticker} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

        # API rate limit ë°©ì§€
        if (idx + 1) % batch_size == 0:
            time.sleep(1)

    print(f"\n{'='*60}")
    print(f"âœ… ì„±ê³µ: {success_count}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {fail_count}ê°œ")
    print(f"ğŸ“Š ì´ê³„: {success_count + fail_count}ê°œ ì²˜ë¦¬")
    print(f"{'='*60}\n")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸš€ S&P 500 ë°ì´í„°ë² ì´ìŠ¤ í™•ì¥ ì‹œì‘")
    print("=" * 60)

    # 1. S&P 500 ì „ì²´ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (ìœ„í‚¤í”¼ë””ì•„)
    sp500_df = get_sp500_tickers()
    if sp500_df.empty:
        print("âŒ S&P 500 ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 2. SECì—ì„œ CIK ë§¤í•‘ ê°€ì ¸ì˜¤ê¸°
    cik_map = get_cik_map()

    # 3. í˜„ì¬ DBì— ìˆëŠ” í‹°ì»¤ í™•ì¸
    existing_tickers = get_existing_tickers()

    # 4. ì¶”ê°€í•  ê¸°ì—… ì°¾ê¸°
    missing_df = get_missing_companies(sp500_df, existing_tickers)

    if missing_df.empty:
        print("âœ… ëª¨ë“  S&P 500 ê¸°ì—…ì´ ì´ë¯¸ DBì— ìˆìŠµë‹ˆë‹¤!")
        return

    # 5. ì‚¬ìš©ì í™•ì¸
    print(f"\nâš ï¸  {len(missing_df)}ê°œ ê¸°ì—…ì„ ì¶”ê°€í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ", end="")
    confirm = input().strip().lower()

    if confirm != "y":
        print("âŒ ì‘ì—… ì·¨ì†Œë¨")
        return

    # 6. í•œê¸€ ì´ë¦„ ë²ˆì—­ (ë°°ì¹˜ ì²˜ë¦¬)
    print("\nğŸ“ í•œê¸€ ì´ë¦„ ë²ˆì—­ ì¤‘...")
    company_names = missing_df["company_name"].tolist()
    korean_names = translate_batch(company_names)
    print(f"   {len(korean_names)}ê°œ í•œê¸€ ì´ë¦„ ë²ˆì—­ ì™„ë£Œ")

    # 7. DBì— ì¶”ê°€
    add_companies_to_db(missing_df, cik_map, korean_names)

    print("\nâœ… S&P 500 í™•ì¥ ì™„ë£Œ!")
    print(f"ğŸ“Š ìµœì¢… ê¸°ì—… ìˆ˜: {len(existing_tickers) + len(missing_df)}ê°œ (ì˜ˆìƒ)")
    print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print("   1. python scripts/collect_10k_relationships.py --source supabase")
    print("   2. python scripts/upload_relationships_to_supabase.py")


if __name__ == "__main__":
    main()
