"""
ê¸°ì¡´ ê¸°ì—… ë°ì´í„° ì—…ë°ì´íŠ¸
DBì— ì´ë¯¸ ìˆëŠ” ê¸°ì—…ë“¤ì˜ ëˆ„ë½ëœ í•„ë“œë¥¼ ì±„ì›ë‹ˆë‹¤.

ì—…ë°ì´íŠ¸ ëŒ€ìƒ:
- cik: SEC APIì—ì„œ ê°€ì ¸ì˜¤ê¸°
- korean_name: OpenAI APIë¡œ ë²ˆì—­
- logo_url, website, exchange, market_cap: Finnhub API
- headquarters: ìœ„í‚¤í”¼ë””ì•„ S&P 500 ëª©ë¡ì—ì„œ ê°€ì ¸ì˜¤ê¸°
"""

import os
import sys
import time
import pandas as pd
import requests
from pathlib import Path
from typing import Dict, List, Optional
from dotenv import load_dotenv
from openai import OpenAI

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.data.supabase_client import SupabaseClient
from src.data.finnhub_client import FinnhubClient

load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


def get_existing_companies() -> pd.DataFrame:
    """DBì—ì„œ ëª¨ë“  ê¸°ì—… ê°€ì ¸ì˜¤ê¸°"""
    try:
        client = SupabaseClient.get_client()
        result = client.table("companies").select("*").execute()
        df = pd.DataFrame(result.data)
        print(f"ğŸ“Š DBì—ì„œ {len(df)}ê°œ ê¸°ì—… ë¡œë“œë¨")
        return df
    except Exception as e:
        print(f"âŒ ê¸°ì—… ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()


def get_cik_map() -> Dict[str, str]:
    """SECì—ì„œ í‹°ì»¤-CIK ë§¤í•‘ ê°€ì ¸ì˜¤ê¸°"""
    print("ğŸ“‹ SECì—ì„œ CIK ë§¤í•‘ ë¡œë“œ ì¤‘...")

    headers = {
        "User-Agent": os.getenv("SEC_API_USER_AGENT", "researcher@university.edu"),
        "Accept": "application/json",
    }

    try:
        url = "https://www.sec.gov/files/company_tickers.json"
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        data = response.json()

        cik_map = {}
        for item in data.values():
            ticker = item.get("ticker", "").upper()
            cik = str(item.get("cik_str", "")).zfill(10)
            cik_map[ticker] = cik

        print(f"   {len(cik_map)}ê°œ CIK ë§¤í•‘ ë¡œë“œë¨")
        return cik_map

    except Exception as e:
        print(f"âš ï¸  CIK ë§¤í•‘ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}


def get_sp500_headquarters() -> Dict[str, str]:
    """ìœ„í‚¤í”¼ë””ì•„ì—ì„œ S&P 500 ê¸°ì—… ë³¸ì‚¬ ìœ„ì¹˜ ê°€ì ¸ì˜¤ê¸°"""
    print("ğŸ“‹ ìœ„í‚¤í”¼ë””ì•„ì—ì„œ ë³¸ì‚¬ ì •ë³´ ë¡œë“œ ì¤‘...")
    url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"

    try:
        # User-Agent í—¤ë” ì¶”ê°€ (403 ë°©ì§€)
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()

        tables = pd.read_html(response.text)
        sp500_table = tables[0]

        hq_map = {}
        for _, row in sp500_table.iterrows():
            ticker = str(row["Symbol"]).replace(".", "-")
            headquarters = row.get("Headquarters Location", "")
            if headquarters:
                hq_map[ticker] = headquarters

        print(f"   {len(hq_map)}ê°œ ë³¸ì‚¬ ì •ë³´ ë¡œë“œë¨")
        return hq_map

    except Exception as e:
        print(f"âš ï¸  ë³¸ì‚¬ ì •ë³´ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}


def translate_batch(company_names: List[str], batch_size: int = 20) -> Dict[str, str]:
    """ì—¬ëŸ¬ íšŒì‚¬ëª…ì„ ë°°ì¹˜ë¡œ ë²ˆì—­ (API í˜¸ì¶œ ìµœì†Œí™”)"""
    translations = {}

    print(f"ğŸ“ {len(company_names)}ê°œ ê¸°ì—… í•œê¸€ ì´ë¦„ ë²ˆì—­ ì¤‘...")

    for i in range(0, len(company_names), batch_size):
        batch = company_names[i : i + batch_size]
        batch_text = "\n".join([f"{j+1}. {name}" for j, name in enumerate(batch)])

        try:
            response = openai_client.chat.completions.create(
                model=os.getenv("CHAT_MODEL", "gpt-4.1-mini"),
                messages=[
                    {
                        "role": "system",
                        "content": """ë‹¹ì‹ ì€ ë¯¸êµ­ ê¸°ì—…ëª…ì„ í•œê¸€ë¡œ ë²ˆì—­í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë„ë¦¬ ì•Œë ¤ì§„ í•œê¸€ í‘œê¸°ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ ë°œìŒì„ í•œê¸€ë¡œ í‘œê¸°í•˜ì„¸ìš”.
ê° ì¤„ì— ë²ˆí˜¸ì™€ í•œê¸€ íšŒì‚¬ëª…ë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì˜ˆ: "1. ì• í”Œ""",
                    },
                    {
                        "role": "user",
                        "content": f"ë‹¤ìŒ ë¯¸êµ­ ê¸°ì—…ëª…ë“¤ì„ í•œê¸€ë¡œ ë²ˆì—­í•˜ì„¸ìš”:\n{batch_text}",
                    },
                ],
                max_tokens=1000,
                temperature=0.1,
            )

            result = response.choices[0].message.content.strip()
            lines = result.split("\n")

            for j, line in enumerate(lines):
                if j < len(batch):
                    # "1. ì• í”Œ" í˜•ì‹ì—ì„œ í•œê¸€ëª… ì¶”ì¶œ
                    if ". " in line:
                        korean_name = line.split(". ", 1)[1].strip()
                    else:
                        korean_name = line.strip()
                    translations[batch[j]] = korean_name

            print(f"   ğŸ“ {i+1}~{min(i+batch_size, len(company_names))}ê°œ ë²ˆì—­ ì™„ë£Œ")
            time.sleep(0.5)  # Rate limit

        except Exception as e:
            print(f"   âš ï¸ ë°°ì¹˜ ë²ˆì—­ ì‹¤íŒ¨: {e}")

    return translations


def fetch_finnhub_profile(ticker: str, finnhub_client: FinnhubClient) -> Optional[Dict]:
    """Finnhubì—ì„œ ê¸°ì—… í”„ë¡œí•„ ê°€ì ¸ì˜¤ê¸°"""
    try:
        profile = finnhub_client.get_company_profile(ticker)
        if profile:
            return {
                "exchange": profile.get("exchange", ""),
                "market_cap": profile.get("marketCapitalization", 0),
                "logo_url": profile.get("logo", ""),
                "website": profile.get("weburl", ""),
            }
        return None
    except:
        return None


def update_companies(
    companies_df: pd.DataFrame, cik_map: Dict, hq_map: Dict, korean_names: Dict
):
    """ê¸°ì—… ë°ì´í„° ì—…ë°ì´íŠ¸"""
    client = SupabaseClient.get_client()
    finnhub_client = FinnhubClient()

    total = len(companies_df)
    updated_count = 0

    print(f"\nğŸ“¤ {total}ê°œ ê¸°ì—… ì—…ë°ì´íŠ¸ ì¤‘...")

    for idx, row in companies_df.iterrows():
        ticker = row["ticker"]
        company_name = row["company_name"]

        # ì—…ë°ì´íŠ¸í•  í•„ë“œ ìˆ˜ì§‘
        updates = {}

        # CIK ì—…ë°ì´íŠ¸
        if pd.isna(row.get("cik")) or not row.get("cik"):
            cik = cik_map.get(ticker) or cik_map.get(ticker.replace("-", ""))
            if cik:
                updates["cik"] = cik

        # í•œê¸€ ì´ë¦„ ì—…ë°ì´íŠ¸
        if pd.isna(row.get("korean_name")) or not row.get("korean_name"):
            korean_name = korean_names.get(company_name)
            if korean_name:
                updates["korean_name"] = korean_name

        # ë³¸ì‚¬ ì—…ë°ì´íŠ¸
        if pd.isna(row.get("headquarters")) or not row.get("headquarters"):
            hq = hq_map.get(ticker)
            if hq:
                updates["headquarters"] = hq

        # Finnhub ì •ë³´ ì—…ë°ì´íŠ¸ (logo_url, website, exchange, market_cap)
        needs_finnhub = (
            (pd.isna(row.get("logo_url")) or not row.get("logo_url"))
            or (pd.isna(row.get("website")) or not row.get("website"))
            or (pd.isna(row.get("exchange")) or not row.get("exchange"))
        )

        if needs_finnhub:
            profile = fetch_finnhub_profile(ticker, finnhub_client)
            if profile:
                if not row.get("logo_url") and profile["logo_url"]:
                    updates["logo_url"] = profile["logo_url"]
                if not row.get("website") and profile["website"]:
                    updates["website"] = profile["website"]
                if not row.get("exchange") and profile["exchange"]:
                    updates["exchange"] = profile["exchange"]
                if (
                    not row.get("market_cap") or row.get("market_cap") == 0
                ) and profile["market_cap"]:
                    updates["market_cap"] = profile["market_cap"]

        # ì—…ë°ì´íŠ¸ ì‹¤í–‰
        if updates:
            try:
                result = (
                    client.table("companies")
                    .update(updates)
                    .eq("ticker", ticker)
                    .execute()
                )
                if result.data:
                    updated_count += 1
                    kr_display = (
                        f" ({updates.get('korean_name', '')})"
                        if updates.get("korean_name")
                        else ""
                    )
                    print(
                        f"  âœ… [{updated_count}] {ticker}{kr_display} - ì—…ë°ì´íŠ¸: {list(updates.keys())}"
                    )
            except Exception as e:
                print(f"  âŒ {ticker} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

        # Rate limit
        if (idx + 1) % 10 == 0:
            time.sleep(0.5)

    print(f"\n{'='*60}")
    print(f"âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: {updated_count}ê°œ ê¸°ì—…")
    print(f"{'='*60}\n")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸ”„ ê¸°ì¡´ ê¸°ì—… ë°ì´í„° ì—…ë°ì´íŠ¸")
    print("=" * 60)

    # 1. ê¸°ì¡´ ê¸°ì—… ê°€ì ¸ì˜¤ê¸°
    companies_df = get_existing_companies()
    if companies_df.empty:
        print("âŒ ê¸°ì—… ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 2. ì—…ë°ì´íŠ¸ í•„ìš”í•œ ê¸°ì—… í™•ì¸
    missing_cik = companies_df[
        companies_df["cik"].isna() | (companies_df["cik"] == "")
    ].shape[0]
    missing_korean = companies_df[
        companies_df["korean_name"].isna() | (companies_df["korean_name"] == "")
    ].shape[0]
    missing_hq = companies_df[
        companies_df["headquarters"].isna() | (companies_df["headquarters"] == "")
    ].shape[0]
    missing_logo = companies_df[
        companies_df["logo_url"].isna() | (companies_df["logo_url"] == "")
    ].shape[0]

    print(f"\nğŸ“‹ ì—…ë°ì´íŠ¸ í•„ìš”:")
    print(f"   - CIK ì—†ìŒ: {missing_cik}ê°œ")
    print(f"   - í•œê¸€ ì´ë¦„ ì—†ìŒ: {missing_korean}ê°œ")
    print(f"   - ë³¸ì‚¬ ì •ë³´ ì—†ìŒ: {missing_hq}ê°œ")
    print(f"   - ë¡œê³  URL ì—†ìŒ: {missing_logo}ê°œ")

    if (
        missing_cik == 0
        and missing_korean == 0
        and missing_hq == 0
        and missing_logo == 0
    ):
        print("\nâœ… ëª¨ë“  ê¸°ì—… ë°ì´í„°ê°€ ì™„ì „í•©ë‹ˆë‹¤!")
        return

    # 3. ì‚¬ìš©ì í™•ì¸
    print(f"\nâš ï¸  ì—…ë°ì´íŠ¸í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ", end="")
    confirm = input().strip().lower()

    if confirm != "y":
        print("âŒ ì‘ì—… ì·¨ì†Œë¨")
        return

    # 4. ë°ì´í„° ì†ŒìŠ¤ ë¡œë“œ
    cik_map = get_cik_map()
    hq_map = get_sp500_headquarters()

    # 5. í•œê¸€ ì´ë¦„ ë²ˆì—­ (ì—†ëŠ” ê²ƒë§Œ)
    companies_needing_korean = companies_df[
        companies_df["korean_name"].isna() | (companies_df["korean_name"] == "")
    ]["company_name"].tolist()

    korean_names = {}
    if companies_needing_korean:
        korean_names = translate_batch(companies_needing_korean)

    # 6. ì—…ë°ì´íŠ¸ ì‹¤í–‰
    update_companies(companies_df, cik_map, hq_map, korean_names)

    print("âœ… ê¸°ì¡´ ê¸°ì—… ì—…ë°ì´íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
