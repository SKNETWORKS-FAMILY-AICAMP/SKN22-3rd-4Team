"""
Model Settings - ì¤‘ì•™ ì§‘ì¤‘ì‹ ëª¨ë¸ ì„¤ì •
ëª¨ë“  AI ëª¨ë¸ ê´€ë ¨ ì„¤ì •ì„ ì—¬ê¸°ì„œ ê´€ë¦¬
"""

import os
from dotenv import load_dotenv

load_dotenv()


# =============================================================================
# EMBEDDING MODELS
# =============================================================================

EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "text-embedding-3-small")
EMBEDDING_DIMENSIONS = 1536


# =============================================================================
# CHAT MODELS
# =============================================================================

# Analyst Chatbot (ëŒ€í™”í˜• ë¶„ì„)
CHAT_MODEL = os.getenv("CHAT_MODEL", "gpt-4.1-mini")
CHAT_MAX_TOKENS = 2000

# Graph RAG (ê´€ê³„ ë¶„ì„)
GRAPH_MODEL = os.getenv("GRAPH_MODEL", "gpt-4.1-mini")
GRAPH_MAX_TOKENS = 1500


# =============================================================================
# REPORT MODELS (Standardized to gpt-4.1-mini)
# =============================================================================

REPORT_MODEL = os.getenv("REPORT_MODEL", "gpt-4.1-mini")
REPORT_MAX_TOKENS = 3000
COMPARISON_MAX_TOKENS = 4000

# gpt-5-nano ì „ìš© ì„¤ì •
REPORT_MODEL_CONFIG = {
    "response_format": {"type": "text"},
    "verbosity": "medium",
    "reasoning_effort": "medium",
    "store": False,
}


# =============================================================================
# API KEYS
# =============================================================================

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
FINNHUB_API_KEY = os.getenv("FINNHUB_API_KEY")


# =============================================================================
# MODEL HELPERS
# =============================================================================


def get_report_params(max_tokens: int = None) -> dict:
    """gpt-5-nano API í˜¸ì¶œìš© íŒŒë¼ë¯¸í„° ë°˜í™˜"""
    params = {
        "model": REPORT_MODEL,
        "max_completion_tokens": max_tokens or REPORT_MAX_TOKENS,
        **REPORT_MODEL_CONFIG,
    }
    return params


def get_chat_params() -> dict:
    """ì±—ë´‡ API í˜¸ì¶œìš© íŒŒë¼ë¯¸í„° ë°˜í™˜"""
    return {
        "model": CHAT_MODEL,
        "max_completion_tokens": CHAT_MAX_TOKENS,
    }


# =============================================================================
# VALIDATION
# =============================================================================


def validate_api_keys() -> dict:
    """API í‚¤ ìƒíƒœ í™•ì¸"""
    return {
        "openai": bool(OPENAI_API_KEY),
        "finnhub": bool(FINNHUB_API_KEY)
        and FINNHUB_API_KEY != "your_finnhub_api_key_here",
    }


if __name__ == "__main__":
    print("ğŸ“Š Model Settings")
    print("=" * 40)
    print(f"Embedding: {EMBEDDING_MODEL}")
    print(f"Chat: {CHAT_MODEL}")
    print(f"Report: {REPORT_MODEL}")
    print(f"Graph: {GRAPH_MODEL}")
    print()
    print("API Keys:", validate_api_keys())
